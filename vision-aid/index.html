<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>VisionAid: Navigation for Visually Impaired</title>
  <link href="src/output.css" rel="stylesheet">
</head>
<body class="bg-gray-100 flex flex-col items-center justify-center min-h-screen">
  <div class="text-center p-4">
    <h1 class="text-2xl font-bold mb-4">VisionAid: Navigation Assistant</h1>
    <p class="text-lg mb-4">Grant camera access to detect objects. Point at the center of an object, 1â€“3 meters away, in a well-lit room.</p>
    <button id="startBtn" class="bg-blue-500 text-white px-4 py-2 rounded hover:bg-blue-600" onclick="startCamera()">Start Camera</button>
    <video id="video" class="mt-4 hidden" autoplay playsinline></video>
    <canvas id="canvas" class="hidden"></canvas>
    <p id="status" class="text-lg mt-4">Status: Waiting for camera permission...</p>
  </div>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const status = document.getElementById('status');
    let ctx, ws;
    const FRAME_RATE = 300;  // Reduced
    const CANVAS_WIDTH = 640;
    const CANVAS_HEIGHT = 480;
    let lastSpokenObjects = new Map();
    const SPEECH_TIMEOUT = 10000;
    let isSpeaking = false;
    let speechQueue = [];
    let lastObjectKey = null;

    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: 'environment' }
        });
        video.srcObject = stream;
        video.classList.remove('hidden');
        canvas.classList.remove('hidden');
        canvas.width = CANVAS_WIDTH;
        canvas.height = CANVAS_HEIGHT;
        ctx = canvas.getContext('2d');
        status.textContent = 'Status: Camera active, connecting to backend...';
        speak('Camera active, connecting to backend.');
        console.log('Camera initialized:', stream.getVideoTracks()[0].getSettings());
        connectWebSocket();
      } catch (err) {
        status.textContent = 'Error: Failed to access camera. Please grant permission.';
        speak('Error: Failed to access camera. Please grant permission.');
        console.error('Camera error:', err);
      }
    }

    function connectWebSocket() {
      ws = new WebSocket('wss://07dc-103-133-230-22.ngrok-free.app/ws');
      ws.onopen = () => {
        status.textContent = 'Status: Connected to backend, detecting objects...';
        speak('Connected to backend, starting object detection.');
        console.log('WebSocket connected');
        sendFrames();
      };
      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        console.log('Received predictions at:', new Date().toISOString());
        processPredictions(data.predictions);
      };
      ws.onerror = (error) => {
        status.textContent = 'Status: WebSocket error.';
        speak('Error connecting to backend.');
        console.error('WebSocket error:', error);
      };
      ws.onclose = () => {
        status.textContent = 'Status: WebSocket disconnected. Reconnecting...';
        console.log('WebSocket disconnected');
        setTimeout(connectWebSocket, 5000);
      };
    }

    function sendFrames() {
      if (ws.readyState !== WebSocket.OPEN) return;

      ctx.drawImage(video, 0, 0, CANVAS_WIDTH, CANVAS_HEIGHT);
      const frame = canvas.toDataURL('image/jpeg', 0.8);
      ws.send(frame);

      setTimeout(sendFrames, FRAME_RATE);
    }

    function processPredictions(predictions) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      console.log('Predictions:', predictions);

      let detected = false;
      const currentTime = Date.now();
      const currentObjects = new Set();

      for (const [obj, time] of lastSpokenObjects) {
        if (currentTime - time > SPEECH_TIMEOUT) {
          lastSpokenObjects.delete(obj);
        }
      }

      if (predictions.length === 0) {
        status.textContent = 'Status: No objects detected. Point at the center of an object.';
        console.log('No objects detected');
        speechQueue = [];
        lastObjectKey = null;
        return;
      }

      predictions.forEach(pred => {
        detected = true;
        const [x, y, width, height] = pred.bbox;
        const objectName = pred.class;
        const confidence = pred.confidence;
        const direction = pred.direction;

        ctx.beginPath();
        ctx.rect(x, y, width, height);
        ctx.lineWidth = 2;
        ctx.strokeStyle = 'red';
        ctx.stroke();
        ctx.fillStyle = 'red';
        ctx.fillText(`${objectName} (${(confidence * 100).toFixed(1)}%)`, x, y - 10);

        const objKey = objectName;
        currentObjects.add(objKey);

        if (objKey !== lastObjectKey && !lastSpokenObjects.has(objKey)) {
          const message = `${objectName} detected on ${direction}`;
          lastSpokenObjects.set(objKey, currentTime);
          speechQueue = [message];
          lastObjectKey = objKey;
          console.log(`Queueing speech: ${message}, Confidence: ${confidence}, BBox: [${x}, ${y}, ${width}, ${height}]`);
        }
      });

      for (const obj of lastSpokenObjects.keys()) {
        if (!currentObjects.has(obj)) {
          lastSpokenObjects.delete(obj);
        }
      }

      if (detected) {
        status.textContent = 'Status: Detecting object...';
      }

      processSpeechQueue();
    }

    function processSpeechQueue() {
      if (isSpeaking || speechQueue.length === 0) return;

      const message = speechQueue.shift();
      speak(message);
    }

    function speak(text) {
      if (isSpeaking) {
        window.speechSynthesis.cancel();
      }
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.rate = 1.2;
      utterance.volume = 1;
      utterance.lang = 'en-US';
      utterance.onstart = () => { isSpeaking = true; };
      utterance.onend = () => {
        isSpeaking = false;
        setTimeout(processSpeechQueue, 500);
      };
      window.speechSynthesis.speak(utterance);  // Removed delay
    }

    document.getElementById('startBtn').focus();
  </script>
</body>
</html>